{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Thêm thư viện\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 1. preprocessing image label\n",
    "# 1.1 pick image path\n",
    "image_path = list(paths.list_images('/home/coffeeaddicted/Documents/Document/AI/Course/Ai4e/Cifar100/dataset/'))\n",
    "\n",
    "# 1.2 random suffle image path\n",
    "random.shuffle(image_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1.3 pick label of image\n",
    "labels = []\n",
    "for i in range(len(image_path)):\n",
    "    label = image_path[i].split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "print(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 1.4 transform labels into number\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 1.5 transform labels into binary\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 2. preprocess image\n",
    "# load images and resized into input size of VGG16\n",
    "list_images = []\n",
    "for (j,image_path) in enumerate(image_path):\n",
    "    image = load_img(image_path,target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image,0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "    list_images.append(image)\n",
    "list_images = np.vstack(list_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(list_images.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1360, 224, 224, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected layer ở cuối.\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Xây thêm các layer\n",
    "# Lấy output của ConvNet trong VGG16\n",
    "fcHead = baseModel.output\n",
    "\n",
    "# Flatten trước khi dùng FCs\n",
    "fcHead = Flatten(name='flatten')(fcHead)\n",
    "\n",
    "# Thêm FC\n",
    "fcHead = Dense(256, activation='relu')(fcHead)\n",
    "fcHead = Dropout(0.5)(fcHead)\n",
    "\n",
    "# Output layer với softmax activation\n",
    "fcHead = Dense(17, activation='softmax')(fcHead)\n",
    "\n",
    "# Xây dựng model bằng việc nối ConvNet của VGG16 và fcHead\n",
    "model = model = Model(inputs=baseModel.input, outputs=fcHead)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 69s 1us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# separate data into 80%\n",
    "x_train, x_test, y_train, y_test = train_test_split(list_images,labels, train_size=0.8, random_state= 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# augmentation cho training data\n",
    "aug_train = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, \n",
    "                         zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "# augementation cho test\n",
    "aug_test= ImageDataGenerator(rescale=1./255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# freeze VGG model\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = RMSprop(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "numOfEpoch = 25\n",
    "H = model.fit_generator(aug_train.flow(x_train, y_train, batch_size=32), \n",
    "                        steps_per_epoch=len(x_train)//32,\n",
    "                        validation_data=(aug_test.flow(x_test, y_test, batch_size=32)),\n",
    "                        validation_steps=len(x_test)//32,\n",
    "                        epochs=numOfEpoch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# unfreeze some last CNN layer:\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "numOfEpoch = 35\n",
    "opt = SGD(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "H = model.fit_generator(aug_train.flow(x_train, y_train, batch_size=32), \n",
    "                        steps_per_epoch=len(x_train)//32,\n",
    "                        validation_data=(aug_test.flow(x_test, y_test, batch_size=32)),\n",
    "                        validation_steps=len(x_test)//32,\n",
    "                        epochs=numOfEpoch)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "d8f54f19d88e051e72ef3eb8c29534107549a0c7b24a7c8e60b74598e47a86c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}